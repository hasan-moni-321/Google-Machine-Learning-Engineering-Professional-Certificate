{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Using Machine Learning APIs </h1>\n",
    "\n",
    "First, visit <a href=\"http://console.cloud.google.com/apis\">API console</a>, choose \"Credentials\" on the left-hand menu.  Choose \"Create Credentials\" and generate an API key for your application. You should probably restrict it by IP address to prevent abuse, but for now, just  leave that field blank and delete the API key after trying out this demo.\n",
    "\n",
    "Copy-paste your API Key here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the chown command to change the ownership of repository to user\n",
    "!sudo chown -R jupyter:jupyter /home/jupyter/training-data-analyst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "APIKEY=\"AIzaSyC7V5RyaXbsyQNrB1egPMhgF-ap7oxGNhQ\"  # Replace with your API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Note: Make sure you generate an API Key and replace the value above. The sample key will not work.</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Invoke Translate API </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is it really this easy? -> est-ce vraiment si facile ?\n",
      "amazing technology -> technologie étonnante\n",
      "wow -> Wow\n"
     ]
    }
   ],
   "source": [
    "# Running the Translate API\n",
    "from googleapiclient.discovery import build\n",
    "service = build('translate', 'v2', developerKey=APIKEY)\n",
    "\n",
    "# Use the service\n",
    "inputs = ['is it really this easy?', 'amazing technology', 'wow']\n",
    "outputs = service.translations().list(source='en', target='fr', q=inputs).execute()\n",
    "\n",
    "# Print outputs\n",
    "for input, output in zip(inputs, outputs['translations']):\n",
    "  print(\"{0} -> {1}\".format(input, output['translatedText']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Invoke Vision API </h2>\n",
    "\n",
    "The Vision API can work off an image in Cloud Storage or embedded directly into a POST message. I'll use Cloud Storage and do OCR on this image: <img src=\"https://storage.googleapis.com/cloud-training-demos/vision/sign2.jpg\" width=\"200\" />.  That photograph is from http://www.publicdomainpictures.net/view-image.php?image=15842\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'responses': [{'textAnnotations': [{'locale': 'zh', 'description': '请您爱护和保\\n护卫生创建优\\n美水环境\\n', 'boundingPoly': {'vertices': [{'x': 125, 'y': 104}, {'x': 1071, 'y': 104}, {'x': 1071, 'y': 655}, {'x': 125, 'y': 655}]}}, {'description': '请', 'boundingPoly': {'vertices': [{'x': 184, 'y': 104}, {'x': 319, 'y': 104}, {'x': 319, 'y': 239}, {'x': 184, 'y': 239}]}}, {'description': '您', 'boundingPoly': {'vertices': [{'x': 336, 'y': 104}, {'x': 463, 'y': 104}, {'x': 463, 'y': 239}, {'x': 336, 'y': 239}]}}, {'description': '爱护', 'boundingPoly': {'vertices': [{'x': 480, 'y': 112}, {'x': 767, 'y': 112}, {'x': 767, 'y': 239}, {'x': 480, 'y': 239}]}}, {'description': '和', 'boundingPoly': {'vertices': [{'x': 784, 'y': 112}, {'x': 919, 'y': 112}, {'x': 919, 'y': 239}, {'x': 784, 'y': 239}]}}, {'description': '保', 'boundingPoly': {'vertices': [{'x': 936, 'y': 104}, {'x': 1071, 'y': 104}, {'x': 1071, 'y': 231}, {'x': 936, 'y': 231}]}}, {'description': '护', 'boundingPoly': {'vertices': [{'x': 125, 'y': 280}, {'x': 331, 'y': 280}, {'x': 331, 'y': 451}, {'x': 125, 'y': 451}]}}, {'description': '卫生', 'boundingPoly': {'vertices': [{'x': 333, 'y': 280}, {'x': 675, 'y': 280}, {'x': 675, 'y': 451}, {'x': 333, 'y': 451}]}}, {'description': '创建', 'boundingPoly': {'vertices': [{'x': 677, 'y': 280}, {'x': 991, 'y': 280}, {'x': 991, 'y': 451}, {'x': 677, 'y': 451}]}}, {'description': '优', 'boundingPoly': {'vertices': [{'x': 993, 'y': 280}, {'x': 1047, 'y': 280}, {'x': 1047, 'y': 451}, {'x': 993, 'y': 451}]}}, {'description': '美', 'boundingPoly': {'vertices': [{'x': 152, 'y': 504}, {'x': 295, 'y': 504}, {'x': 295, 'y': 647}, {'x': 152, 'y': 647}]}}, {'description': '水', 'boundingPoly': {'vertices': [{'x': 312, 'y': 504}, {'x': 447, 'y': 504}, {'x': 447, 'y': 647}, {'x': 312, 'y': 647}]}}, {'description': '环境', 'boundingPoly': {'vertices': [{'x': 472, 'y': 504}, {'x': 767, 'y': 504}, {'x': 767, 'y': 655}, {'x': 472, 'y': 655}]}}], 'fullTextAnnotation': {'pages': [{'property': {'detectedLanguages': [{'languageCode': 'zh', 'confidence': 0.75}]}, 'width': 1280, 'height': 818, 'blocks': [{'property': {'detectedLanguages': [{'languageCode': 'zh', 'confidence': 0.75}]}, 'boundingBox': {'vertices': [{'x': 125, 'y': 104}, {'x': 1071, 'y': 104}, {'x': 1071, 'y': 655}, {'x': 125, 'y': 655}]}, 'paragraphs': [{'property': {'detectedLanguages': [{'languageCode': 'zh', 'confidence': 0.75}]}, 'boundingBox': {'vertices': [{'x': 125, 'y': 104}, {'x': 1071, 'y': 104}, {'x': 1071, 'y': 655}, {'x': 125, 'y': 655}]}, 'words': [{'property': {'detectedLanguages': [{'languageCode': 'zh'}]}, 'boundingBox': {'vertices': [{'x': 184, 'y': 104}, {'x': 319, 'y': 104}, {'x': 319, 'y': 239}, {'x': 184, 'y': 239}]}, 'symbols': [{'property': {'detectedLanguages': [{'languageCode': 'zh'}]}, 'boundingBox': {'vertices': [{'x': 184, 'y': 104}, {'x': 319, 'y': 104}, {'x': 319, 'y': 239}, {'x': 184, 'y': 239}]}, 'text': '请'}]}, {'property': {'detectedLanguages': [{'languageCode': 'zh'}]}, 'boundingBox': {'vertices': [{'x': 336, 'y': 104}, {'x': 463, 'y': 104}, {'x': 463, 'y': 239}, {'x': 336, 'y': 239}]}, 'symbols': [{'property': {'detectedLanguages': [{'languageCode': 'zh'}]}, 'boundingBox': {'vertices': [{'x': 336, 'y': 104}, {'x': 463, 'y': 104}, {'x': 463, 'y': 239}, {'x': 336, 'y': 239}]}, 'text': '您'}]}, {'property': {'detectedLanguages': [{'languageCode': 'zh'}]}, 'boundingBox': {'vertices': [{'x': 480, 'y': 112}, {'x': 767, 'y': 112}, {'x': 767, 'y': 239}, {'x': 480, 'y': 239}]}, 'symbols': [{'property': {'detectedLanguages': [{'languageCode': 'zh'}]}, 'boundingBox': {'vertices': [{'x': 480, 'y': 112}, {'x': 615, 'y': 112}, {'x': 615, 'y': 239}, {'x': 480, 'y': 239}]}, 'text': '爱'}, {'property': {'detectedLanguages': [{'languageCode': 'zh'}]}, 'boundingBox': {'vertices': [{'x': 632, 'y': 112}, {'x': 767, 'y': 112}, {'x': 767, 'y': 239}, {'x': 632, 'y': 239}]}, 'text': '护'}]}, {'property': {'detectedLanguages': [{'languageCode': 'zh'}]}, 'boundingBox': {'vertices': [{'x': 784, 'y': 112}, {'x': 919, 'y': 112}, {'x': 919, 'y': 239}, {'x': 784, 'y': 239}]}, 'symbols': [{'property': {'detectedLanguages': [{'languageCode': 'zh'}]}, 'boundingBox': {'vertices': [{'x': 784, 'y': 112}, {'x': 919, 'y': 112}, {'x': 919, 'y': 239}, {'x': 784, 'y': 239}]}, 'text': '和'}]}, {'property': {'detectedLanguages': [{'languageCode': 'zh'}]}, 'boundingBox': {'vertices': [{'x': 936, 'y': 104}, {'x': 1071, 'y': 104}, {'x': 1071, 'y': 231}, {'x': 936, 'y': 231}]}, 'symbols': [{'property': {'detectedLanguages': [{'languageCode': 'zh'}], 'detectedBreak': {'type': 'EOL_SURE_SPACE'}}, 'boundingBox': {'vertices': [{'x': 936, 'y': 104}, {'x': 1071, 'y': 104}, {'x': 1071, 'y': 231}, {'x': 936, 'y': 231}]}, 'text': '保'}]}, {'property': {'detectedLanguages': [{'languageCode': 'zh'}]}, 'boundingBox': {'vertices': [{'x': 125, 'y': 280}, {'x': 331, 'y': 280}, {'x': 331, 'y': 451}, {'x': 125, 'y': 451}]}, 'symbols': [{'property': {'detectedLanguages': [{'languageCode': 'zh'}]}, 'boundingBox': {'vertices': [{'x': 125, 'y': 280}, {'x': 331, 'y': 280}, {'x': 331, 'y': 451}, {'x': 125, 'y': 451}]}, 'text': '护'}]}, {'property': {'detectedLanguages': [{'languageCode': 'zh'}]}, 'boundingBox': {'vertices': [{'x': 333, 'y': 280}, {'x': 675, 'y': 280}, {'x': 675, 'y': 451}, {'x': 333, 'y': 451}]}, 'symbols': [{'property': {'detectedLanguages': [{'languageCode': 'zh'}]}, 'boundingBox': {'vertices': [{'x': 333, 'y': 280}, {'x': 503, 'y': 280}, {'x': 503, 'y': 451}, {'x': 333, 'y': 451}]}, 'text': '卫'}, {'property': {'detectedLanguages': [{'languageCode': 'zh'}]}, 'boundingBox': {'vertices': [{'x': 504, 'y': 280}, {'x': 675, 'y': 280}, {'x': 675, 'y': 451}, {'x': 504, 'y': 451}]}, 'text': '生'}]}, {'property': {'detectedLanguages': [{'languageCode': 'zh'}]}, 'boundingBox': {'vertices': [{'x': 677, 'y': 280}, {'x': 991, 'y': 280}, {'x': 991, 'y': 451}, {'x': 677, 'y': 451}]}, 'symbols': [{'property': {'detectedLanguages': [{'languageCode': 'zh'}]}, 'boundingBox': {'vertices': [{'x': 677, 'y': 280}, {'x': 819, 'y': 280}, {'x': 819, 'y': 451}, {'x': 677, 'y': 451}]}, 'text': '创'}, {'property': {'detectedLanguages': [{'languageCode': 'zh'}]}, 'boundingBox': {'vertices': [{'x': 820, 'y': 280}, {'x': 991, 'y': 280}, {'x': 991, 'y': 451}, {'x': 820, 'y': 451}]}, 'text': '建'}]}, {'property': {'detectedLanguages': [{'languageCode': 'zh'}]}, 'boundingBox': {'vertices': [{'x': 993, 'y': 280}, {'x': 1047, 'y': 280}, {'x': 1047, 'y': 451}, {'x': 993, 'y': 451}]}, 'symbols': [{'property': {'detectedLanguages': [{'languageCode': 'zh'}], 'detectedBreak': {'type': 'EOL_SURE_SPACE'}}, 'boundingBox': {'vertices': [{'x': 993, 'y': 280}, {'x': 1047, 'y': 280}, {'x': 1047, 'y': 451}, {'x': 993, 'y': 451}]}, 'text': '优'}]}, {'boundingBox': {'vertices': [{'x': 152, 'y': 504}, {'x': 295, 'y': 504}, {'x': 295, 'y': 647}, {'x': 152, 'y': 647}]}, 'symbols': [{'boundingBox': {'vertices': [{'x': 152, 'y': 504}, {'x': 295, 'y': 504}, {'x': 295, 'y': 647}, {'x': 152, 'y': 647}]}, 'text': '美'}]}, {'boundingBox': {'vertices': [{'x': 312, 'y': 504}, {'x': 447, 'y': 504}, {'x': 447, 'y': 647}, {'x': 312, 'y': 647}]}, 'symbols': [{'boundingBox': {'vertices': [{'x': 312, 'y': 504}, {'x': 447, 'y': 504}, {'x': 447, 'y': 647}, {'x': 312, 'y': 647}]}, 'text': '水'}]}, {'boundingBox': {'vertices': [{'x': 472, 'y': 504}, {'x': 767, 'y': 504}, {'x': 767, 'y': 655}, {'x': 472, 'y': 655}]}, 'symbols': [{'boundingBox': {'vertices': [{'x': 472, 'y': 504}, {'x': 607, 'y': 504}, {'x': 607, 'y': 647}, {'x': 472, 'y': 647}]}, 'text': '环'}, {'property': {'detectedBreak': {'type': 'LINE_BREAK'}}, 'boundingBox': {'vertices': [{'x': 624, 'y': 504}, {'x': 767, 'y': 504}, {'x': 767, 'y': 655}, {'x': 624, 'y': 655}]}, 'text': '境'}]}]}], 'blockType': 'TEXT'}]}], 'text': '请您爱护和保\\n护卫生创建优\\n美水环境\\n'}}]}\n"
     ]
    }
   ],
   "source": [
    "# Running the Vision API\n",
    "import base64\n",
    "IMAGE=\"gs://cloud-training-demos/vision/sign2.jpg\"\n",
    "vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "                    'source': {\n",
    "                        'gcs_image_uri': IMAGE\n",
    "                    }\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': 'TEXT_DETECTION',\n",
    "                    'maxResults': 3,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "responses = request.execute(num_retries=3)\n",
    "\n",
    "# Let's output the `responses`\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zh 请您爱护和保\n",
      "护卫生创建优\n",
      "美水环境\n",
      "\n"
     ]
    }
   ],
   "source": [
    "foreigntext = responses['responses'][0]['textAnnotations'][0]['description']\n",
    "foreignlang = responses['responses'][0]['textAnnotations'][0]['locale']\n",
    "\n",
    "# Let's output the `foreignlang` and `foreigntext`\n",
    "print(foreignlang, foreigntext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Translate sign </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请您爱护和保\n",
      "护卫生创建优\n",
      "美水环境\n",
      " -> Please cherish and protect sanitation and create a beautiful water environment\n"
     ]
    }
   ],
   "source": [
    "inputs=[foreigntext]\n",
    "outputs = service.translations().list(source=foreignlang, target='en', q=inputs).execute()\n",
    "\n",
    "# Print the outputs\n",
    "for input, output in zip(inputs, outputs['translations']):\n",
    "  print(\"{0} -> {1}\".format(input, output['translatedText']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Sentiment analysis with Language API </h2>\n",
    "\n",
    "Let's evaluate the sentiment of some famous quotes using Google Cloud Natural Language API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpError",
     "evalue": "<HttpError 400 when requesting https://language.googleapis.com/v1beta1/documents:analyzeSentiment?key=AIzaSyC7V5RyaXbsyQNrB1egPMhgF-ap7oxGNhQ&alt=json returned \"API Key not found. Please pass a valid API key.\". Details: \"[{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'language.googleapis.com'}}]\">",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-cf5beccc92ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m       'document': {\n\u001b[1;32m     16\u001b[0m          \u001b[0;34m'type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'PLAIN_TEXT'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m          \u001b[0;34m'content'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquote\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       }\n\u001b[1;32m     19\u001b[0m     }).execute()\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    935\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHttpError\u001b[0m: <HttpError 400 when requesting https://language.googleapis.com/v1beta1/documents:analyzeSentiment?key=AIzaSyC7V5RyaXbsyQNrB1egPMhgF-ap7oxGNhQ&alt=json returned \"API Key not found. Please pass a valid API key.\". Details: \"[{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'language.googleapis.com'}}]\">"
     ]
    }
   ],
   "source": [
    "# Evaluating the sentiment with Google Cloud Natural Language API\n",
    "lservice = build('language', 'v1beta1', developerKey=APIKEY)\n",
    "quotes = [\n",
    "  'To succeed, you must have tremendous perseverance, tremendous will.',\n",
    "  'It’s not that I’m so smart, it’s just that I stay with problems longer.',\n",
    "  'Love is quivering happiness.',\n",
    "  'Love is of all passions the strongest, for it attacks simultaneously the head, the heart, and the senses.',\n",
    "  'What difference does it make to the dead, the orphans and the homeless, whether the mad destruction is wrought under the name of totalitarianism or in the holy name of liberty or democracy?',\n",
    "  'When someone you love dies, and you’re not expecting it, you don’t lose her all at once; you lose her in pieces over a long time — the way the mail stops coming, and her scent fades from the pillows and even from the clothes in her closet and drawers. '\n",
    "]\n",
    "for quote in quotes:\n",
    "# The `documents.analyzeSentiment` method analyzes the sentiment of the provided text.\n",
    "  response = lservice.documents().analyzeSentiment(\n",
    "    body={\n",
    "      'document': {\n",
    "         'type': 'PLAIN_TEXT',\n",
    "         'content': quote\n",
    "      }\n",
    "    }).execute()\n",
    "  polarity = response['documentSentiment']['polarity']\n",
    "  magnitude = response['documentSentiment']['magnitude']\n",
    "\n",
    "# Lets output the value of each `polarity`, `magnitude` and `quote`\n",
    "  print('POLARITY=%s MAGNITUDE=%s for %s' % (polarity, magnitude, quote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Speech API </h2>\n",
    "\n",
    "The Speech API can work on streaming data, audio content encoded and embedded directly into the POST message, or on a file on Cloud Storage. Here I'll pass in this <a href=\"https://storage.googleapis.com/cloud-training-demos/vision/audio.raw\">audio file</a> in Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': [{'alternatives': [{'transcript': 'how old is the Brooklyn Bridge', 'confidence': 0.98287845}]}], 'totalBilledTime': '15s'}\n"
     ]
    }
   ],
   "source": [
    "# Using the Speech API by passing audio file as an argument\n",
    "sservice = build('speech', 'v1', developerKey=APIKEY)\n",
    "# The `speech.recognize` method performs synchronous speech recognition.\n",
    "# It receive results after all audio has been sent and processed.\n",
    "response = sservice.speech().recognize(\n",
    "    body={\n",
    "        'config': {\n",
    "            'languageCode' : 'en-US',\n",
    "            'encoding': 'LINEAR16',\n",
    "            'sampleRateHertz': 16000\n",
    "        },\n",
    "        'audio': {\n",
    "            'uri': 'gs://cloud-training-demos/vision/audio.raw'\n",
    "            }\n",
    "        }).execute()\n",
    "\n",
    "# Let's output the value of `response`\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how old is the Brooklyn Bridge\n",
      "Confidence=0.982878\n"
     ]
    }
   ],
   "source": [
    "print(response['results'][0]['alternatives'][0]['transcript'])\n",
    "\n",
    "# Let's output the value of `'Confidence`\n",
    "print('Confidence=%f' % response['results'][0]['alternatives'][0]['confidence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Clean up </h2>\n",
    "\n",
    "Remember to delete the API key by visiting <a href=\"http://console.cloud.google.com/apis\">API console</a>.\n",
    "\n",
    "If necessary, commit all your notebooks to git.\n",
    "\n",
    "If you are running Datalab on a Compute Engine VM or delegating to one, remember to stop or shut it down so that you are not charged.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Exercise\n",
    "\n",
    "Here are a few portraits from the Metropolitan Museum of Art, New York (they are part of a [BigQuery public dataset](https://bigquery.cloud.google.com/dataset/bigquery-public-data:the_met) ):\n",
    "\n",
    "* gs://cloud-training-demos/images/met/APS6880.jpg\n",
    "* gs://cloud-training-demos/images/met/DP205018.jpg\n",
    "* gs://cloud-training-demos/images/met/DP290402.jpg\n",
    "* gs://cloud-training-demos/images/met/DP700302.jpg\n",
    "\n",
    "Use the Vision API to identify which of these images depict happy people and which ones depict unhappy people.\n",
    "\n",
    "Hint (highlight to see): <p style=\"color:white\">You will need to look for joyLikelihood and/or sorrowLikelihood from the response.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Google Inc.\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m76",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m76"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
